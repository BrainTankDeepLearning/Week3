{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAOVF5w6PG7k"
      },
      "source": [
        "## **Welcome to Week Three of BrainTank Deep Learning:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEjpvQlrPFJ4"
      },
      "source": [
        "Lets get started:\n",
        "\n",
        "---\n",
        "\n",
        "First thing we are going to do is run this piece of code that will download important files for this weeks challenge. Take a look at:\n",
        "\n",
        "1.   model.state"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PDPgOCkO9DE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352133fa-1707-4961-e156-a99281994405"
      },
      "source": [
        "!git clone https://github.com/BrainTankDeepLearning/Week3.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Week3'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fACzhBxePWZ_"
      },
      "source": [
        "Helper Functions:\n",
        "---\n",
        "Here I have provided two helper functions that will help us use and view some of the data we working with. You DO NOT need to edit any of these, but feel free to play around with them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E4c0KM_PVni"
      },
      "source": [
        "import torch\n",
        "from torch.nn import Module\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import math\n",
        "import sys\n",
        "\n",
        "random_seed = 3\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "def get_datasets(batch_size = 9):\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                              transform=torchvision.transforms.Compose([\n",
        "                                torchvision.transforms.ToTensor(),\n",
        "                                torchvision.transforms.Normalize(\n",
        "                                  (0.1307,), (0.3081,))\n",
        "                              ])),\n",
        "    batch_size=batch_size, shuffle=False, drop_last = True)\n",
        "\n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                              transform=torchvision.transforms.Compose([\n",
        "                                torchvision.transforms.ToTensor(),\n",
        "                                torchvision.transforms.Normalize(\n",
        "                                  (0.1307,), (0.3081,))\n",
        "                              ])),\n",
        "    batch_size=batch_size, shuffle=False, drop_last = True)\n",
        "  \n",
        "\n",
        "  \n",
        "  return train_loader, test_loader\n",
        "\n",
        "def print_image(image, target = None, prediction = None):\n",
        "  # settings\n",
        "  h, w = 26, 26        # for raster image\n",
        "  nrows, ncols = 3, 3  # array of sub-plots\n",
        "  figsize = [6, 8]     # figure size, inches\n",
        "\n",
        "  # create figure (fig), and array of axes (ax)\n",
        "  fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
        "\n",
        "  # plot simple raster image on each sub-plot\n",
        "  for i, axi in enumerate(ax.flat):\n",
        "    if i >= nrows * ncols:\n",
        "      break\n",
        "    # i runs from 0 to (nrows*ncols-1)\n",
        "    # axi is equivalent with ax[rowid][colid]\n",
        "    img = image[i]\n",
        "    axi.imshow(img.squeeze(), alpha=0.25)\n",
        "    # get indices of row/column\n",
        "    rowid = i // ncols\n",
        "    colid = i % ncols\n",
        "    # write row/col indices as axes' title for identification\n",
        "    if prediction is None and target is not None:\n",
        "      axi.set_title(\"Target:\"+str(target[i].item()))\n",
        "    if prediction is not None and target is None:\n",
        "      axi.set_title(\"Prediction:\" + str(prediction[i].item()))\n",
        "    if prediction is not None and target is not None:\n",
        "      axi.set_title(\"Target:\"+str(target[i].item())+\" Prediction:\" + str(prediction[i].item()))\n",
        "\n",
        "  plt.tight_layout(True)\n",
        "  plt.show()\n",
        "\n",
        "def create_one_hot(labels):\n",
        "  out = torch.empty(size = (len(labels), 10))\n",
        "  for i, label in enumerate(labels):\n",
        "    one_hot = torch.zeros(10)\n",
        "    one_hot[label.item()] = 1\n",
        "    out[i] = one_hot\n",
        "  return out\n",
        "\n",
        "def softmax_loss(prediction, one_hot):\n",
        "  prediction = torch.log(prediction)\n",
        "\n",
        "  target = torch.empty(size = (len(one_hot), ), dtype = torch.long)\n",
        "  for i, row in enumerate(one_hot):\n",
        "    index = (row == 1).nonzero(as_tuple=True)[0]\n",
        "    target[i] = index.item()\n",
        "\n",
        "  loss = torch.nn.functional.nll_loss(prediction, target)\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_zTpVwGPaxl"
      },
      "source": [
        "# Our Tasks:\n",
        "\n",
        "---\n",
        "\n",
        "**1.   Create our own Neural Network Layer class**\n",
        "\n",
        "Helpful Formula for calculate a forward propagation:\n",
        "\n",
        "*   out = in * A^t + b\n",
        "\n",
        "**2.   Create a neural network that we can use to predict the label associated with a image's pixel values**\n",
        "\n",
        "*   Our model will take in a batch of images as inputs and output vector of length 10 with percent values associated with the liklihood it thinks a picture belongs to it's corresponding label\n",
        "\n",
        "**3.   Devize a strategy to test our network and see if it is doin a good or bad job prediciting labels**\n",
        "\n",
        "**4. Save and load our model to prevent needing to retrain the model every time we want to test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSkO7rqIP6tg",
        "outputId": "145d531d-9662-4060-b395-61e493431d16"
      },
      "source": [
        "class NeuralNetworkLayer(torch.nn.Module):\n",
        "  def __init__(self, input_layers : int, output_layers : int):\n",
        "    super(NeuralNetworkLayer, self).__init__()\n",
        "    \n",
        "    self.A = torch.empty(size = (output_layers, input_layers))\n",
        "    self.b = torch.empty(size = (output_layers, ))\n",
        "\n",
        "    self.A = torch.randn_like(self.A)\n",
        "    self.b = torch.randn_like(self.b)\n",
        "\n",
        "    self.A = torch.nn.Parameter(self.A)\n",
        "    self.b = torch.nn.Parameter(self.b)\n",
        "\n",
        "  def forward(self, input_activation):\n",
        "    A_transposed = torch.transpose(self.A, 0, 1)\n",
        "    output_activation = torch.matmul(input_activation, A_transposed)\n",
        "    output_activation_with_bias = output_activation + self.b\n",
        "\n",
        "    return output_activation_with_bias\n",
        "\n",
        "class ScoreClassifier(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ScoreClassifier, self).__init__()\n",
        "    \n",
        "    self.NN_layer1 = NeuralNetworkLayer(784, 400)\n",
        "    self.NN_layer2 = NeuralNetworkLayer(400, 200)\n",
        "    self.NN_layer3 = NeuralNetworkLayer(200, 100)\n",
        "    self.NN_layer4 = NeuralNetworkLayer(100, 10)\n",
        "\n",
        "  def forward(self, image):\n",
        "    image = image.squeeze(dim = 1)\n",
        "    image = image.view(9, 784)\n",
        "\n",
        "    out = self.NN_layer1(image)\n",
        "    out = torch.sigmoid(out)\n",
        "    out = self.NN_layer2(out)\n",
        "    out = torch.sigmoid(out)\n",
        "    out = self.NN_layer3(out)\n",
        "    out = torch.sigmoid(out)\n",
        "    out = self.NN_layer4(out)\n",
        "\n",
        "    out = torch.nn.functional.softmax(out, dim = 1)\n",
        "\n",
        "    return out\n",
        "\n",
        "def train(model, train_dataset, optim):\n",
        "  for epoch_number in range(5):\n",
        "    avg_loss = 0\n",
        "    for data in train_ds:\n",
        "      optim.zero_grad()\n",
        "\n",
        "      images = data[0]\n",
        "      labels = data[1]\n",
        "\n",
        "      prediction = model(images)\n",
        "      ground_truths = create_one_hot(labels)\n",
        "\n",
        "      loss = softmax_loss(prediction, ground_truths)\n",
        "\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "\n",
        "      avg_loss += loss.item()\n",
        "    avg_loss /= (len(train_ds))\n",
        "    print(f\"loss: {avg_loss}\")\n",
        "  \n",
        "  torch.save(model.state_dict(), \"model.state\")\n",
        "\n",
        "def test(model, test_dataset):\n",
        "  total_correct = 0\n",
        "  for data in test_dataset:\n",
        "    images = data[0]\n",
        "    labels = data[1]\n",
        "\n",
        "    prediction = model(images)\n",
        "\n",
        "    max_indexes = torch.argmax(prediction, axis = 1)\n",
        "\n",
        "    n_correct = (max_indexes == labels)\n",
        "    n_correct = torch.sum(n_correct == True).item()\n",
        "\n",
        "    total_correct += n_correct\n",
        "\n",
        "    #print_image(images, target = labels, prediction = max_indexes)\n",
        "\n",
        "  print(\"Accuracy:\", total_correct / len(test_dataset) / 9)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # load the datasets:\n",
        "  train_ds, test_ds = get_datasets(batch_size = 9)\n",
        "\n",
        "  # define the model\n",
        "  model = ScoreClassifier()\n",
        "\n",
        "  if os.path.isfile(\"Week3/model.state\"):\n",
        "    model.load_state_dict(torch.load(\"Week3/model.state\"))\n",
        "    print(\"Loaded model from: model.state\")\n",
        "\n",
        "  # optimizer\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "\n",
        "  # train\n",
        "  train(model, train_ds, optimizer)\n",
        "\n",
        "  # test\n",
        "  test(model, test_ds)\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from: model.state\n",
            "Accuracy: 0.963096309630963\n"
          ]
        }
      ]
    }
  ]
}